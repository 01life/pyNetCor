{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyNetCor Demo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = 1000\n",
    "samples = 100\n",
    "arr1 = np.random.random((features, samples))\n",
    "arr2 = np.random.random((features, samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and return the full matrix at once.\n",
    "\n",
    "from pynetcor.cor import corrcoef\n",
    "\n",
    "cor_default_values = np.corrcoef(arr1)\n",
    "cor_test_values = corrcoef(arr1)\n",
    "\n",
    "assert np.allclose(cor_default_values, cor_test_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-k correlation search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the accurate top k correlations (Pearson correlation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynetcor.cor import cor_topk\n",
    "\n",
    "k = 15\n",
    "\n",
    "# numpy implementation\n",
    "cor_ref = np.corrcoef(arr1).flatten()\n",
    "topk_order = np.argsort(-np.abs(cor_ref))[:k]\n",
    "topk_values = cor_ref[topk_order]\n",
    "val_ref = topk_values\n",
    "\n",
    "# pyNetCor implementation\n",
    "val = cor_topk(arr1, arr1, k=k)[:, 2]\n",
    "\n",
    "assert np.allclose(val, val_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-k differential correlation search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the accurate top k differences in correlation between pairs of features across two states or time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynetcor.cor import cor_topkdiff\n",
    "\n",
    "k = 15\n",
    "\n",
    "# numpy implementation\n",
    "cm1 = np.corrcoef(arr1)\n",
    "cm2 = np.corrcoef(arr2)\n",
    "m_diff = cm1 - cm2\n",
    "v_diff = m_diff.flatten()\n",
    "order = np.argsort(-np.abs(v_diff))\n",
    "topkdiff_ref = np.abs(v_diff[order])[:k]\n",
    "\n",
    "# pynetcor implementation\n",
    "topkdiff = np.abs(\n",
    "    cor_topkdiff(x1=arr1, y1=arr2, x2=arr1, y2=arr2, k=k, method=\"pearson\", threads=8)[\n",
    "        :, 2\n",
    "    ]\n",
    ")\n",
    "\n",
    "assert np.allclose(topkdiff, topkdiff_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-value computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the P-values for correlations (Pearson or Spearman) using the Student's t-distribution. The approximation method is significantly faster than the classical method, with the absolute errors are nearly less than 1e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from pynetcor.cor import pvalue_student_t\n",
    "\n",
    "# scipy pearsonr\n",
    "correlations = []\n",
    "pvalues = []\n",
    "for i in range(arr1.shape[1]):\n",
    "    for j in range(arr1.shape[1]):\n",
    "        r, p = scipy.stats.pearsonr(arr1[:, i], arr1[:, j])\n",
    "        correlations.append(r)\n",
    "        pvalues.append(p)\n",
    "correlations = np.asarray(correlations)\n",
    "pvalues = np.asarray(pvalues)\n",
    "\n",
    "# pyNetCor\n",
    "derived_pvalues = pvalue_student_t(\n",
    "    correlations, arr1.shape[0] - 2, approx=False, threads=8\n",
    ")\n",
    "\n",
    "assert np.all(np.isclose(pvalues, derived_pvalues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unified implementation for calculating correlations and P-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from pynetcor.cor import cortest\n",
    "\n",
    "# Pearson correlation & P-value approximation\n",
    "cortest_result = cortest(arr1.T, approx_pvalue=True, threads=8)\n",
    "\n",
    "# scipy pearsonr\n",
    "correlations = []\n",
    "pvalues = []\n",
    "for i in range(arr1.shape[1]):\n",
    "    for j in range(i + 1, arr1.shape[1]):\n",
    "        r, p = scipy.stats.pearsonr(arr1[:, i], arr1[:, j])\n",
    "        correlations.append(r)\n",
    "        pvalues.append(p)\n",
    "correlations = np.asarray(correlations)\n",
    "pvalues = np.asarray(pvalues)\n",
    "\n",
    "assert np.allclose(cortest_result[:, 2], correlations)\n",
    "assert np.allclose(cortest_result[:, 3], pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chunking computation, recommended for large-scale analysis that exceed RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from pynetcor.cor import chunked_cortest\n",
    "\n",
    "cortest_lst = []\n",
    "for iter in chunked_cortest(arr1.T, approx_pvalue=True, threads=8):\n",
    "    cortest_lst.append(iter)\n",
    "cortest_result = np.concatenate(cortest_lst, axis=0)\n",
    "\n",
    "# scipy pearsonr\n",
    "correlations = []\n",
    "pvalues = []\n",
    "for i in range(arr1.shape[1]):\n",
    "    for j in range(i + 1, arr1.shape[1]):\n",
    "        r, p = scipy.stats.pearsonr(arr1[:, i], arr1[:, j])\n",
    "        correlations.append(r)\n",
    "        pvalues.append(p)\n",
    "correlations = np.asarray(correlations)\n",
    "pvalues = np.asarray(pvalues)\n",
    "\n",
    "assert np.allclose(cortest_result[:, 2], correlations)\n",
    "assert np.allclose(cortest_result[:, 3], pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple testing correction: holm, hochberg, bonferroni, BH, BY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "from pynetcor.cor import cortest\n",
    "\n",
    "# Pearson correlation & multiple testing correction\n",
    "cortest_result = cortest(arr1.T, adjust_pvalue=True, adjust_method=\"BH\", threads=8)\n",
    "\n",
    "# scipy pearsonr & statsmodels multipletests\n",
    "correlations = []\n",
    "pvalues = []\n",
    "for i in range(arr1.shape[1]):\n",
    "    for j in range(i + 1, arr1.shape[1]):\n",
    "        r, p = scipy.stats.pearsonr(arr1[:, i], arr1[:, j])\n",
    "        correlations.append(r)\n",
    "        pvalues.append(p)\n",
    "correlations = np.asarray(correlations)\n",
    "pvalues = np.asarray(pvalues)\n",
    "adjusted_pvalues = multipletests(pvalues, method=\"fdr_bh\")[1]\n",
    "\n",
    "assert np.allclose(cortest_result[:, 4], adjusted_pvalues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
